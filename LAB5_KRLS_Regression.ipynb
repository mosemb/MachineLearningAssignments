{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 05 - Kernel Regularized Least Squares\n",
    "\n",
    "In this lab activity we consider the extension of Regularized Least Squares to non-linear problems using kernel functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 1 - Define a function to generate D-dimensional synthetic data non non-linear regression problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonLinearRegrFunction(n, D, low_D, high_D, W, sigma_noise,omega,t,sigma):\n",
    "   \n",
    "    X = np.zeros((n,D))\n",
    "    for i in range(0, D):\n",
    "        X[:,i] = np.random.uniform(low_D[i], high_D[i], size=n)\n",
    "    \n",
    "    gauss_noise = np.random.normal(0, sigma_noise, size=(n,1))\n",
    "\n",
    "    Y = np.dot(X*np.exp(-sigma * t) * np.sin(omega * t), W) + gauss_noise\n",
    "     \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200\n",
    "D = 2\n",
    "w = np.array([1,1]).transpose()\n",
    "w.shape = (D,1)\n",
    "\n",
    "omega = 0.1 * 2 * np.pi\n",
    "t = 20\n",
    "sigma = 0.1\n",
    "\n",
    "low_D = np.array([-1, -1])\n",
    "high_D = np.array([1, 1])\n",
    "\n",
    "# Here we can compute the true function\n",
    "Xtrue, Ytrue = nonLinearRegrFunction(n, D, low_D, high_D, w, 0.8,omega,t,sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrue1, Ytrue1 = nonLinearRegrFunction(n, D, low_D, high_D, w, 0.8,omega,t,sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrue1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function <b>sqDist</b> computes all the distances between two sets of points stored in two matrices X1 and X2. Use it as follows:\n",
    "\n",
    "##### D = sqDist(X1, X2)\n",
    "where\n",
    "- X1: a matrix of size [n1xd], where each row is a d-dimensional point\n",
    "- X2: a matrix of size [n2xd], where each row is a d-dimensional point\n",
    "- D: a [n1xn2] matrix where each element (D)_ij is the distance between points (X_i, X_j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqDist(X1, X2):\n",
    "    sqx = np.multiply(X1, X1) +1\n",
    "    sqy = np.multiply(X2, X2)+1\n",
    "    return np.outer(sqx, np.ones(sqy.shape[0])) + np.outer(np.ones(sqx.shape[0]), sqy.T) - 2 * np.dot(X1, X2.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function <b>kernelMatrix</b> builds the matrix of the kernel (also called Gram matrix) between two sets of points stored in two matrices X1 and X2. Use is as follows:\n",
    "\n",
    "##### K = kernelMatrix(X1, X2, kernel_type, param)\n",
    "where\n",
    "- X1, X2: collections of points on which to compute the Gram matrix\n",
    "- kernel: can be 'linear', 'polynomial' or 'gaussian'\n",
    "- param: is [] for the linear kernel, the exponent of the polynomial kernel, or the standard deviation for the gaussian kernel\n",
    "- K: Gram matrix\n",
    "\n",
    "### TASK 2 - Complete the computation of the kernel matrix depending on the specific kernel choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernelMatrix(X1, X2, kernel_type, param):\n",
    "   \n",
    "    if kernel_type == 'linear':\n",
    "        return  np.dot(X1.T,X2)\n",
    "    elif kernel_type == 'polynomial':\n",
    "        return  np.power((np.dot(X1.T,X2)+1),param) \n",
    "    elif kernel_type == 'gaussian':\n",
    "        return np.exp((np.power(-np.linalg.norm(X1-X2),2))/2*param**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function <b>regularizedKernLSTrain</b> computes the parameters of the function estimated on the training set. Use it as follows:\n",
    "\n",
    "##### c = regularizedKernLSTrain(Xtr, Ytr, kernel, sigma, lam)\n",
    "where\n",
    "- Xtr: training input\n",
    "- Ytr: training output\n",
    "- kernel_type: type of kernel ('linear', 'polynomial', 'gaussian')\n",
    "- param: is [] for the linear kernel, the exponent of the polynomial kernel, or the standard deviation for the gaussian kernel\n",
    "- reg_par: regularization parameter\n",
    "- c: model coefficients\n",
    "\n",
    "### TASK 3 - Complete the computation of the c coefficients for the case when square loss is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularizedKernLSTrain(Xtr, Ytr, kernel_type, param, reg_par):\n",
    "   \n",
    "    n = Xtr.shape[0]\n",
    "    K = kernelMatrix(Xtr, Xtr, kernel_type, param)\n",
    "    Z = reg_par * np.eye(Xtr.shape[0])\n",
    "    #inv = np.linalg.inv(K+Z)\n",
    "    c =  np.dot(np.linalg.inv(K+Z),Ytr) #c = (K+Î»I)**-1(y) \n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=regularizedKernLSTrain(Xtrue[:,0], Ytrue, 'linear', 0.9, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function <b>regularizedKernLSTest</b> applies an estimated function (previously called also model) to a test set, to verify its goodness. Use it as follows:\n",
    "\n",
    "##### Ypred = regularizedKernLSTest(c, Xtr, kernel_type, param, Xte)\n",
    "where\n",
    "- c: model coefficients\n",
    "- Xtr: training input\n",
    "- kernel type: type of kernel ('linear', 'polynomial', 'gaussian')\n",
    "- param: is [] for the linear kernel, the exponent of the polynomial kernel, or the standard deviation for the gaussian kernel\n",
    "- Xte: test points\n",
    "- Ypred: predicted output on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularizedKernLSTest(c, Xtr, kernel_type, param, Xte):\n",
    "   \n",
    "    Ktest = kernelMatrix(Xte, Xtr, kernel_type, param)\n",
    "    Ypred = np.dot(Ktest, c)\n",
    "\n",
    "    return Ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred = regularizedKernLSTest(c, Xtrue[:,0], 'linear', 0.6,Xtrue[:,0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function <b>calcErr</b> computes the error between real and predicted output (for regression problems). Use it as follows:\n",
    "\n",
    "##### err = calcErr(Ypred, Ytrue)\n",
    "\n",
    "where\n",
    "- Ypred: estimated (predicted) output\n",
    "- Ytrue: true (correct) output\n",
    "- err: error estimated as Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcErr(Ypred, Ytrue):\n",
    "    return np.mean((Ypred-Ytrue)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.72477605195408"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcErr(Ypred, Ytrue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's modify the function for <b>V-Fold Cross Validation</b>, you already used in the previous labs, to adapt it to the use with Kernel Regularized Least Squares "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VFoldCVKernRLS(x, y, KF, kernel_type, lam_list, kerpar_list):\n",
    "   \n",
    "    if KF <= 0:\n",
    "        print(\"Please supply a positive number of repetitions\")\n",
    "        return -1\n",
    "\n",
    "    if isinstance(kerpar_list, int):\n",
    "        kerpar_list = np.array([kerpar_list])\n",
    "    else:\n",
    "        kerpar_list = np.array(kerpar_list)\n",
    "    nkerpar = kerpar_list.size\n",
    "\n",
    "    if isinstance(lam_list, int):\n",
    "        lam_list = np.array([lam_list])\n",
    "    else:\n",
    "        lam_list = np.array(lam_list)\n",
    "    nlambda = lam_list.size\n",
    "\n",
    "    n = Xtr.shape[0]\n",
    "    n_val = int(np.ceil(n/KF))\n",
    "    ntr = n - n_val\n",
    "\n",
    "    tm = np.zeros((nlambda, nkerpar))\n",
    "    ts = np.zeros((nlambda, nkerpar))\n",
    "    vm = np.zeros((nlambda, nkerpar))\n",
    "    vs = np.zeros((nlambda, nkerpar))\n",
    "\n",
    "    ym = float(y.max() + y.min()) / float(2)\n",
    "    \n",
    "     # Random permutation of training data\n",
    "    rand_idx = np.random.choice(n, size=n, replace=False)\n",
    "\n",
    "    il = 0\n",
    "    for l in lam_list:\n",
    "        iss = 0\n",
    "        for s in kerpar_list:\n",
    "            trerr = np.zeros((KF, 1))\n",
    "            vlerr = np.zeros((KF, 1))\n",
    "            first=0\n",
    "            for fold in range(KF):\n",
    "                \n",
    "                flags = np.zeros(Xtr.shape[0])\n",
    "                flags[first:first+n_val]=1;\n",
    "            \n",
    "                X = Xtr[rand_idx[flags==0]]\n",
    "                Y = Ytr[rand_idx[flags==0]]\n",
    "                X_val = Xtr[rand_idx[flags==1]]\n",
    "                Y_val = Ytr[rand_idx[flags==1]]\n",
    "\n",
    "                c = regularizedKernLSTrain(X, Y, kernel_type, s, l)\n",
    "                \n",
    "                trerr[fold] = calcErr(regularizedKernLSTest(c, X, kernel_type, s, X), Y)\n",
    "                vlerr[fold] = calcErr(regularizedKernLSTest(c, X, kernel_type, s, X_val), Y_val)\n",
    "                \n",
    "            tm[il, iss] = np.median(trerr)\n",
    "            ts[il, iss] = np.std(trerr)\n",
    "            vm[il, iss] = np.median(vlerr)\n",
    "            vs[il, iss] = np.std(vlerr)\n",
    "            iss = iss + 1\n",
    "        il = il + 1\n",
    "    row, col = np.where(vm == np.amin(vm))\n",
    "    l = lam_list[row]\n",
    "    s = kerpar_list[col]\n",
    "\n",
    "    return [l, s, vm, vs, tm, ts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now, let's move to the analysis..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 4 - Build a training and a test set using the function to generate synthetica data for non-linear regression problems you defined with TASK 1\n",
    "\n",
    "Generate, for instance, 2-dimensional data in the range [-1, 1] with sigma_noise = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Ytr =   nonLinearRegrFunction(n, D, low_D, high_D, w, 0.8,omega,t,sigma)\n",
    "Xte, Yte =   nonLinearRegrFunction(n, D, low_D, high_D, w, 0.8,omega,t,sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr[:,0].shape\n",
    "Ytrue.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "kerpar_list = [0.5] # for the time being let's use only one possible value for the kernel parameter\n",
    "lam_list = [10, 7, 5, 2, 1, 0.7, 0.5, 0.3, 0.2, 0.1, 0.05, 0.02, 0.01, 0.005, 0.002, 0.001, 0.0005, 0.0002, 0.0001, 0.00001, 0.000001]\n",
    "V_Fold = 5\n",
    "\n",
    "#, s, vm, vs, tm, ts = VFoldCVKernRLS(Xtrue[:,1] ,Ytrue, 5, \"linear\" , lam_list, kerpar_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 5 - Complete, where required, the final parts, considering first a gaussian and then a polynomial kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c9766613489c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using gaussian kernel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msemilogx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlam_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msemilogx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlam_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Training error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Validation error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tm' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAASrUlEQVR4nO3df7BndV3H8ecLlhV/8KPatXKXgMYl3ciUrojTD2kwhR3drSwHkgqHxCzsh+hE1hhhU6alkyOma6mpCaxazE23MA0zlTUuEYxA2Logu2TDqkAUJSy+++Ocbb/e7t3v9977vfcu9/N8zNyZ7znnc855n8/e+/qe7+ec79lUFZKkle+w5S5AkrQ0DHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+BqbJDcnOX2561hsi3WcSS5J8r5xb3cedXwiyc8tdx0av1XLXYAOLUkK2FBVOwfmXQI8sarOPdi6VfXdi1zeIaGV49TK4xm+tMIk8UROMzLwNSdJ1iT5cJJ7k3w1yT8kOaxfdkeSZ/evL0myLcl7ktzfD4NMDGznlCQ39Ms+kOTKJL8zyz4PT/KHSb6c5PYkFyap/cGW5MVJbu23tSvJSwfWPS/Jp6Ztr5I8sX+9Kckt/bp3JXnlHI/z1CTX9u2+lOQtSVZP29fPJ/nXvs1lSTJCPx+R5PIkH0qyOskT+td7+z74pYG2lyT5YJL3JfkP4Lx+WOa1ST7dH9tHk6wZWOe0JJ/pa7qxhaE4Gfiau4uAPcBa4FuBVwOzPZ9jM3AFcCwwCbwFoA/EvwTeDXwzcDnwYwfZ50uAs4CnAqcAPzpt+d3A84CjgRcDb0pyyojH86fAS6vqKOBk4O/6+aMe58PArwJrgGcCZwC/MK3N84CnA08BXgg892AFJXk0cBXwtb79PuCvgBuBdf0+fiXJ4Ha2AB+k6+s/7+f9FF1/PB5YDex/M1sHfAT4Hbr+fyXwoSRrD1aXHvkMfM3VQ8C3A8dX1UNV9Q81+wOZPlVV26vqYeC9wPf280+ju3705n4bfwH840H2+ULgj6pqT1XdA7xucGFVfaSqvlCdvwc+CvzgHI5nY5Kjq+qeqvqnuRxnVV1fVTuqal9V3QG8HXjWtGavq6p7q+pO4Bq6N67ZHA38DfAF4MV93z0dWFtVl1bVg1W1C3gHcPbAetdW1VVV9fWq+u9+3ruq6vP99LaB/Z4LbO//bb5eVX8LTAGbhneXHskMfE33MHDEtHlH0AUgwBuAncBH++GTiw+yrX8feP0AcGQ/DPME4K5pAbr7INt5wrTl39A2yVlJdvRDL/fSBdcaRvOCvv0Xk/x9kmf280c6ziQn9UM//94Pp/zuDPue3g+PO0g9p9F9EnjdQP8cDzyhH365tz/GV9N98thvpv6bbb/HAz85bXs/QPcGpxXMwNd0dwInTJt3IvBFgKq6v6ouqqrvpBuyeUWSM+a4jy8B66aNZR83pP36mdomeRTwIeAPgG+tqmOB7cD+bf8X8JiB9t82uOGquq6qttANe1xFdyY8l+P8Y+Bf6O5sOpouiIeO0R/ER4HfAz6eZH+g7wZur6pjB36OqqrBM/K5PPZ2N/Deadt7bFW9buiaekQz8DXdlcBvJlmf5LD+4uTz6caHSfK8JE/sw/o+uk8EX5/jPq7t17swyaokW4BTD9J+G/DLSdYlORb4tYFlq4FHAXuBfUnOAp4zsPxG4LuTPDXJkcAl+xf0F0NflOSYqnoI+I/9xzKH4zyqX+8/kzwJeNno3TCzqno98H660F9DN9x1f5JfS/LodBexT07y9Hnu4n3A85M8t9/WkUlOT7J+6Jp6RDPwNd2lwGeATwH3AK8HXlRVn+uXbwA+BvwnXXC/taqumcsOqupB4MeB84F76caUP0x3kXIm76A7870JuIHuDH4f8HBV3Q/8Et2bwj10FyonB/b1+f6YPgb8a39cg34auKMfjvl54EVzPM5X9vu8v6/zylH6YJiqei3dJ46PAcfQXfh9KnA78GXgT/r589n2brqLvK+me6PcDbwK82DFi/8Big4FST4LvK2q3jVC27P6tscvfmXSyuE7upZFkmcl+bZ+SOdn6S5U/s0sbR/d3y+/qr+l8LfobuuUNAdDAz/JO5PcneRzsyxPkjcn2Znkpjnc/6y2fRfd+Pq9dPe8/0RVfWmWtgF+m27I5gbgVuA1S1GktJIMHdJJ8kN045jvqaqTZ1i+CXg53a1tz6C7X/oZi1CrJGkBhp7hV9Unga8epMkWujeDqqodwLFJvJ9Xkg4x43jI0jq+8Usfe/p5/+/jeZILgAsAHvvYx37fk570pDHsXpLacf3113+5qub1GIwlfapeVW0FtgJMTEzU1NTUUu5ekh7xknxxvuuO4y6du/jGb0mu7+dJkg4h4wj8SeBn+rt1TgPuO8jdFpKkZTJ0SCfJ5cDpwJoke+jugT4CoKreRvetx010D5p6gO5xrJKkQ8zQwK+qc4YsL+AXx1aRJGlR+E1bSWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpESMFfpIzk9yWZGeSi2dY/h1JrklyQ5Kbkmwaf6mSpIUYGvhJDgcuA84CNgLnJNk4rdlvAtuq6mnA2cBbx12oJGlhRjnDPxXYWVW7qupB4Apgy7Q2BRzdvz4G+LfxlShJGodRAn8dsHtgek8/b9AlwLlJ9gDbgZfPtKEkFySZSjK1d+/eeZQrSZqvcV20PQd4d1WtBzYB703y/7ZdVVuraqKqJtauXTumXUuSRjFK4N8FHDcwvb6fN+h8YBtAVV0LHAmsGUeBkqTxGCXwrwM2JDkxyWq6i7KT09rcCZwBkOTJdIHvmI0kHUKGBn5V7QMuBK4GbqW7G+fmJJcm2dw3uwh4SZIbgcuB86qqFqtoSdLcrRqlUVVtp7sYOzjvNQOvbwG+f7ylSZLGyW/aSlIjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWrESIGf5MwktyXZmeTiWdq8MMktSW5O8v7xlilJWqhVwxokORy4DPgRYA9wXZLJqrploM0G4NeB76+qe5I8frEKliTNzyhn+KcCO6tqV1U9CFwBbJnW5iXAZVV1D0BV3T3eMiVJCzVK4K8Ddg9M7+nnDToJOCnJp5PsSHLmTBtKckGSqSRTe/funV/FkqR5GddF21XABuB04BzgHUmOnd6oqrZW1URVTaxdu3ZMu5YkjWKUwL8LOG5gen0/b9AeYLKqHqqq24HP070BSJIOEaME/nXAhiQnJlkNnA1MTmtzFd3ZPUnW0A3x7BpjnZKkBRoa+FW1D7gQuBq4FdhWVTcnuTTJ5r7Z1cBXktwCXAO8qqq+slhFS5LmLlW1LDuemJioqampZdm3JD1SJbm+qibms67ftJWkRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhoxUuAnOTPJbUl2Jrn4IO1ekKSSTIyvREnSOAwN/CSHA5cBZwEbgXOSbJyh3VHALwOfHXeRkqSFG+UM/1RgZ1XtqqoHgSuALTO0ey3w+8D/jLE+SdKYjBL464DdA9N7+nn/J8kpwHFV9ZGDbSjJBUmmkkzt3bt3zsVKkuZvwRdtkxwGvBG4aFjbqtpaVRNVNbF27dqF7lqSNAejBP5dwHED0+v7efsdBZwMfCLJHcBpwKQXbiXp0DJK4F8HbEhyYpLVwNnA5P6FVXVfVa2pqhOq6gRgB7C5qqYWpWJJ0rwMDfyq2gdcCFwN3Apsq6qbk1yaZPNiFyhJGo9VozSqqu3A9mnzXjNL29MXXpYkadz8pq0kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRowU+EnOTHJbkp1JLp5h+SuS3JLkpiQfT3L8+EuVJC3E0MBPcjhwGXAWsBE4J8nGac1uACaq6inAB4HXj7tQSdLCjHKGfyqws6p2VdWDwBXAlsEGVXVNVT3QT+4A1o+3TEnSQo0S+OuA3QPTe/p5szkf+OuZFiS5IMlUkqm9e/eOXqUkacHGetE2ybnABPCGmZZX1daqmqiqibVr145z15KkIVaN0OYu4LiB6fX9vG+Q5NnAbwDPqqqvjac8SdK4jHKGfx2wIcmJSVYDZwOTgw2SPA14O7C5qu4ef5mSpIUaGvhVtQ+4ELgauBXYVlU3J7k0yea+2RuAxwEfSPLPSSZn2ZwkaZmMMqRDVW0Htk+b95qB188ec12SpDHzm7aS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjRgr8JGcmuS3JziQXz7D8UUmu7Jd/NskJ4y5UkrQwQwM/yeHAZcBZwEbgnCQbpzU7H7inqp4IvAn4/XEXKklamFHO8E8FdlbVrqp6ELgC2DKtzRbgz/rXHwTOSJLxlSlJWqhVI7RZB+wemN4DPGO2NlW1L8l9wLcAXx5slOQC4IJ+8mtJPjefolegNUzrq4bZFwfYFwfYFwd813xXHCXwx6aqtgJbAZJMVdXEUu7/UGVfHGBfHGBfHGBfHJBkar7rjjKkcxdw3MD0+n7ejG2SrAKOAb4y36IkSeM3SuBfB2xIcmKS1cDZwOS0NpPAz/avfwL4u6qq8ZUpSVqooUM6/Zj8hcDVwOHAO6vq5iSXAlNVNQn8KfDeJDuBr9K9KQyzdQF1rzT2xQH2xQH2xQH2xQHz7ot4Ii5JbfCbtpLUCANfkhqx6IHvYxkOGKEvXpHkliQ3Jfl4kuOXo86lMKwvBtq9IEklWbG35I3SF0le2P9u3Jzk/Utd41IZ4W/kO5Jck+SG/u9k03LUudiSvDPJ3bN9VymdN/f9dFOSU0bacFUt2g/dRd4vAN8JrAZuBDZOa/MLwNv612cDVy5mTcv1M2Jf/DDwmP71y1rui77dUcAngR3AxHLXvYy/FxuAG4Bv6qcfv9x1L2NfbAVe1r/eCNyx3HUvUl/8EHAK8LlZlm8C/hoIcBrw2VG2u9hn+D6W4YChfVFV11TVA/3kDrrvPKxEo/xeALyW7rlM/7OUxS2xUfriJcBlVXUPQFXdvcQ1LpVR+qKAo/vXxwD/toT1LZmq+iTdHY+z2QK8pzo7gGOTfPuw7S524M/0WIZ1s7Wpqn3A/scyrDSj9MWg8+newVeioX3Rf0Q9rqo+spSFLYNRfi9OAk5K8ukkO5KcuWTVLa1R+uIS4Nwke4DtwMuXprRDzlzzBFjiRytoNEnOBSaAZy13LcshyWHAG4HzlrmUQ8UqumGd0+k+9X0yyfdU1b3LWtXyOAd4d1X9YZJn0n3/5+Sq+vpyF/ZIsNhn+D6W4YBR+oIkzwZ+A9hcVV9botqW2rC+OAo4GfhEkjvoxignV+iF21F+L/YAk1X1UFXdDnye7g1gpRmlL84HtgFU1bXAkXQPVmvNSHky3WIHvo9lOGBoXyR5GvB2urBfqeO0MKQvquq+qlpTVSdU1Ql01zM2V9W8Hxp1CBvlb+QqurN7kqyhG+LZtZRFLpFR+uJO4AyAJE+mC/y9S1rloWES+Jn+bp3TgPuq6kvDVlrUIZ1avMcyPOKM2BdvAB4HfKC/bn1nVW1etqIXyYh90YQR++Jq4DlJbgEeBl5VVSvuU/CIfXER8I4kv0p3Afe8lXiCmORyujf5Nf31it8CjgCoqrfRXb/YBOwEHgBePNJ2V2BfSZJm4DdtJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqxP8Cvoh0bJIkGT8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "kerpar_list = [0.5] # for the time being let's use only one possible value for the kernel parameter\n",
    "lam_list = [10, 7, 5, 2, 1, 0.7, 0.5, 0.3, 0.2, 0.1, 0.05, 0.02, 0.01, 0.005, 0.002, 0.001, 0.0005, 0.0002, 0.0001, 0.00001, 0.000001]\n",
    "V_Fold = 5\n",
    "\n",
    "#l, s, vm, vs, tm, ts = VFoldCVKernRLS(Xtr[:,1], Ytr, 5, kernel_type, lam_list, kerpar_list)\n",
    "\n",
    "fig, axs = plt.subplots(1,  1)\n",
    "plt. title('Using gaussian kernel')\n",
    "plt.semilogx(lam_list, tm, 'r')\n",
    "plt.semilogx(lam_list, vm, 'b')\n",
    "plt.legend(['Training error', 'Validation error'])\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "params = [1,3,4]\n",
    "\n",
    "# Now let's train the model with the best value for the parameters \n",
    "c = regularizedKernLSTrain(Xtr, Ytr, 'gaussian', param=s[0], reg_par=l[0])\n",
    "\n",
    "# Predict the output on the test set with the estimated model\n",
    "Ypred =  regularizedKernLSTest(c, Xtr, kernel_type, param, Xte)\n",
    "\n",
    "# Compute the error between predicted and real output\n",
    "err =  calcErr(Ypred, Ytr)\n",
    "\n",
    "print('Test error: '+str(err)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = regularizedKernLSTrain(Xtr[:,1], Ytr, 'gaussian', param=0.9 , reg_par=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kerpar_list = [4] # for the time being let's use only one possible value for the kernel parameter\n",
    "lam_list = [5, 2, 1, 0.7, 0.5, 0.3, 0.2, 0.1, 0.05, 0.02, 0.01, 0.005, 0.002, 0.001, 0.0005, 0.0002, 0.0001,0.00001,0.000001]\n",
    "V_Fold = 5\n",
    "\n",
    "l, s, vm, vs, tm, ts = VFoldCVKernRLS( # fill here\n",
    "\n",
    "fig, axs = plt.subplots(1,  1)\n",
    "plt. title('Using polynomial kernel')\n",
    "plt.semilogx(lam_list, tm, 'r')\n",
    "plt.semilogx(lam_list, vm, 'b')\n",
    "plt.legend(['Training error', 'Validation error'])\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Now let's train the model with the best value for the parameters \n",
    "c = regularizedKernLSTrain(Xtr, Ytr, 'polynomial', param=s[0], reg_par=l[0])\n",
    "\n",
    "# Predict the output on the test set with the estimated model\n",
    "Ypred = # fill here\n",
    "\n",
    "# Compute the error between predicted and real output\n",
    "err = # fill here\n",
    "\n",
    "print('Test error: '+str(err))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
